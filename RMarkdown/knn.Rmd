---
title: "KNN"
author: Tomás Sánchez Grigioni
output: html_notebook
---

# Bibliotecas

```{r}
library(tidyverse)
library(caret)
library(pROC)

source("../R/Utils.R")
```

# Constantes y otros

```{r}
# ARCHIVOS
PATH_DATOS_IN <- "../data/bd_final.csv"

FILE_COLUMN_SEPARATOR <- ";"
FILE_DECIMAL_SEPARATOR <- "."

# CARET

# División datos
SEED <- 12345
PORCENTAJE_TRAIN <- 0.7

# Pre-procesamiento
PRE_PROCESS_NORMALIZAR <- "range"
PRE_PROCESS_ESTANDARIZAR <- c("center", "scale")

# Grid
K_MIN <- 3
K_MAX <- 25

# Train control
METODO_CROSS_VALIDATION <- "cv"
K_FOLD <- 10

# Train
METODO_KNN <- "knn"

# Curva ROC
NOMBRE_NIVEL_POSITIVO_VAR_RESPUESTA <-  "true"
NOMBRE_VAR_RESPUESTA <-  "diagnostico_pro"
TYPE_PREDICT_KNN <-  "prob"
```

# Cargar datos

```{r}
datos_crudos <- read.table(PATH_DATOS_IN, header = TRUE, sep = FILE_COLUMN_SEPARATOR, dec = FILE_DECIMAL_SEPARATOR)
```

# Manipulación de datos

```{r}
glimpse(datos_crudos)
```
Solo hacemos que las variables que aparecen como <chr> pasen a ser factores

```{r}
datos <- datos_crudos %>% 
  map_dfr(~ if(is.character(.x)) { as.factor(.x) } else { .x })

glimpse(datos)
```

# Aplicar algoritmo KNN

## Ejemplo sencillo

Para hacer algo sencillo, solo usamos dos variables numéricas individuales

```{r}
vars_knn_sencillo <- c("diagnostico_pro", "d1", "d2")
```

Creamos un nuevo df con las variables elegidas

```{r}
df_knn_sencillo <- datos %>% select(all_of(vars_knn_sencillo))
glimpse(df_knn_sencillo)
```

Hacemos un pequeño grafico de d1 vs d2 mostrando a que clase de diagnostico_pro pertenece

```{r}
ggplot(df_knn_sencillo, aes(d1, d2, color = diagnostico_pro, shape = diagnostico_pro)) +
  geom_point() +
  theme_bw()
```
Observamos que se solapan bastante estos datos, pero igual vamos a aplicar el algoritmo para hacer el ejemplo.

```{r}
# Particionar datos
set.seed(SEED)

indices_train <- createDataPartition(df_knn_sencillo$diagnostico_pro, p = PORCENTAJE_TRAIN, list = FALSE) %>% as.vector()

df_knn_sencillo_train <- df_knn_sencillo[indices_train,]
df_knn_sencillo_test <- df_knn_sencillo[-indices_train,]

nrow(df_knn_sencillo_test)
nrow(df_knn_sencillo_train)
```

En este algoritmo hay que definir un valor de k. Para esto lo que vamos a usar es el método de 10-fold cross-validation.

```{r}
# Definimos todos los valores de k a probar.
# Observamos como se debe llamar el parámetro según el modelo que voy a usar, para nuestro caso "knn".
#getModelInfo(model = "knn")

grid <- expand.grid(k = seq(K_MIN, K_MAX))
grid
```

Ahora, tenemos que especificar la forma de que vamos a obtener el valor de k óptimo.

```{r}
train_control <- trainControl(method = METODO_CROSS_VALIDATION, number = K_FOLD)
```


Normalizamos los datos, es decir que los dejamos en el rango [0, 1]. Para esto especificamos el parámetro preProcess en la función train. También, se puede hacer por separado.

Ajustamos el algoritmo a los datos

```{r}
set.seed(SEED)

knn_sencillo <- train(diagnostico_pro ~ ., 
                      data = df_knn_sencillo_train, 
                      method = METODO_KNN, 
                      preProcess = PRE_PROCESS_NORMALIZAR, 
                      tuneGrid = grid, 
                      trControl = train_control)
knn_sencillo

# Este paquete también nos permite graficar como varía la métrica usada para elegir el valor de k óptimo
plot(knn_sencillo)
```

Por último vemos como perfoma el modelo con el test

```{r}
graficar_curva_roc(knn_sencillo, 
                   df_knn_sencillo_test, 
                   nivel_positivo = NOMBRE_NIVEL_POSITIVO_VAR_RESPUESTA, 
                   var_respuesta = NOMBRE_VAR_RESPUESTA,
                   type_predict = TYPE_PREDICT_KNN)
```

## Ejemplo Más Complejo

```{r}
vars_knn_complejo <- c("diagnostico_pro", "d1", "d2", "d3", "d4", "d5", "edad", "es_cuidador", "educ", "empleo", "genero")
df_knn_complejo <- datos %>% select(all_of(vars_knn_complejo)) %>% drop_na()
glimpse(df_knn_complejo)
```
Primero vamos a hacer un preprocesamiento de los datos. Basicamente serán dos tareas:

* Normalizar los datos: (x - xmin) / (xmax - xmin).
* Crear dummy variables para todas las categóricas, excepto la daignostico_pro.

Comenzamos con la normaliación.
```{r}
# Separamos, para que todo lo que hagamos no afecte a la var respuesta
df_x <- df_knn_complejo[,1]
df_y <- df_knn_complejo[,-1]

# Normalizamos los datos, esta función ignora a las factores así que en realidad no pasa nada por tener todas las predictoras juntas.
df_y_normalizado <- df_y %>% 
  preProcess(method = PRE_PROCESS_NORMALIZAR) %>% 
  predict(df_y) %>% 
  data.frame()

# Verificamos que se haya realizado correctamente, ahora todos los xmin y xmax son 0 y 1 respectivamente
df_y_normalizado %>% 
  select(where(is.numeric)) %>% 
  summary()

```
Creamos las variables dummy 

```{r}
# Creación variables dummy
df_y_normalizado_dummy <- dummyVars(~., df_y_normalizado) %>% 
  predict(df_y_normalizado) %>% 
  data.frame()

# Una vez hecho esto podemos vovler a juntar los datos
df_knn_complejo_split <- cbind(df_x, df_y_normalizado_dummy)
```

Separamos los datos

```{r}
set.seed(SEED)
indices_train <- createDataPartition(df_knn_complejo_split$diagnostico_pro, p = PORCENTAJE_TRAIN)[[1]]

df_knn_complejo_train <- df_knn_complejo_split[indices_train,]
df_knn_complejo_test <- df_knn_complejo_split[-indices_train,]

# Verificamos
nrow(df_knn_complejo_split) == nrow(df_knn_complejo_test) + nrow(df_knn_complejo_train)
```
Para buscar el K óptimo, vamos a utilizar 10-fold cross-validation. Vamos a usar valores de k desde 3 hasta 20

```{r}
# Grilla con los valores de k
grid_train <- expand.grid(k = seq(K_MIN, K_MAX))

# Control de entrenamineto
trian_control <- trainControl(method = METODO_CROSS_VALIDATION, number = K_FOLD)
```

Entrenamos el modelo

```{r}
knn_complejo <- train(diagnostico_pro ~ .,
                      df_knn_complejo_train,
                      method = METODO_KNN,
                      tuneGrid = grid_train)

knn_complejo
```

Solo porque podemos, vemos el gráfico de cómo elige el Kmax

```{r}
plot(knn_complejo)
```

Observamos como es el AUROC

```{r}
graficar_curva_roc(knn_complejo,
                   df_knn_complejo_test, 
                   nivel_positivo = NOMBRE_NIVEL_POSITIVO_VAR_RESPUESTA, 
                   var_respuesta = NOMBRE_VAR_RESPUESTA, 
                   type_predict = TYPE_PREDICT_KNN)
```

