---
title: "KNN"
author: Tomás Sánchez Grigioni
output: 
  html_notebook: 
    toc: yes
---

# Bibliotecas

```{r, results = 'hide', collapse = TRUE}
library(tidyverse)
library(caret)
library(pROC)

source("../R/Utils.R")
```

# Constantes y otros

```{r}
# ARCHIVOS
PATH_DATOS_IN <- "../data/bd_final.csv"

FILE_COLUMN_SEPARATOR <- ";"
FILE_DECIMAL_SEPARATOR <- "."

# CARET

# División datos
SEED <- 12345
PORCENTAJE_TRAIN <- 0.7

# Pre-procesamiento
PRE_PROCESS_NORMALIZAR <- "range"
PRE_PROCESS_ESTANDARIZAR <- c("center", "scale")

# Grid
K_MIN <- 3
K_MAX <- 25
AVANCE_k <- 1

# Train control
METODO_CROSS_VALIDATION <- "cv"
K_FOLD <- 10

# Train
METODO_KNN <- "knn"

# Curva ROC
NOMBRE_NIVEL_POSITIVO_VAR_RESPUESTA <-  "true"
NOMBRE_VAR_RESPUESTA <-  "diagnostico_pro"
TYPE_PREDICT_KNN <-  "prob"
```

# Cargar datos

```{r}
datos_crudos <- read.table(PATH_DATOS_IN, header = TRUE, sep = FILE_COLUMN_SEPARATOR, dec = FILE_DECIMAL_SEPARATOR)
```

# Manipulación de datos

```{r, results = 'hide'}
glimpse(datos_crudos)
```
Solo hacemos que las variables que aparecen como <chr> pasen a ser factores

```{r, results = 'hide'}
datos <- datos_crudos %>% 
  map_dfr(~ if(is.character(.x)) { as.factor(.x) } else { .x })

glimpse(datos)
```

# Aplicar algoritmo KNN

## Ejemplo sencillo

Para hacer algo sencillo, solo usamos dos variables numéricas individuales

```{r}
vars_knn_sencillo <- c("diagnostico_pro", "d1", "d2")
```

Creamos un nuevo df con las variables elegidas

```{r, results = 'hide'}
df_knn_sencillo <- datos %>% select(all_of(vars_knn_sencillo))
glimpse(df_knn_sencillo)
```

Hacemos un pequeño grafico de d1 vs d2 mostrando a que clase de diagnostico_pro pertenece

```{r}
ggplot(df_knn_sencillo, aes(d1, d2, color = diagnostico_pro, shape = diagnostico_pro)) +
  geom_point() +
  theme_bw()
```
Observamos que se solapan bastante estos datos, pero igual vamos a aplicar el algoritmo para hacer el ejemplo.

Vamos a normalizar los datos

```{r}
df_knn_sencillo_split <- df_knn_sencillo %>% 
  preProcess(method = PRE_PROCESS_NORMALIZAR) %>% 
  predict(df_knn_sencillo) %>% 
  data.frame()

# Verificamos que se haya realizado correctamente
df_knn_sencillo_split %>% 
  select(where(is.numeric)) %>% 
  summary()
```

Dividimos los datos

```{r}
# Particionar datos
set.seed(SEED)

indices_train <- createDataPartition(df_knn_sencillo_split$diagnostico_pro, p = PORCENTAJE_TRAIN, list = FALSE) %>% as.vector()

df_knn_sencillo_train <- df_knn_sencillo_split[indices_train,]
df_knn_sencillo_test <- df_knn_sencillo_split[-indices_train,]

nrow(df_knn_sencillo_test)
nrow(df_knn_sencillo_train)
```

En este algoritmo hay que definir un valor de k. Para esto lo que vamos a usar es el método de 10-fold cross-validation.

```{r}
# Definimos todos los valores de k a probar.
# Observamos como se debe llamar el parámetro según el modelo que voy a usar, para nuestro caso "knn".
#getModelInfo(model = "knn")

grid <- expand.grid(k = seq(K_MIN, K_MAX))
grid
```

Ahora, tenemos que especificar la forma de que vamos a obtener el valor de k óptimo.

```{r}
train_control <- trainControl(method = METODO_CROSS_VALIDATION, number = K_FOLD)
```


Normalizamos los datos, es decir que los dejamos en el rango [0, 1]. Para esto especificamos el parámetro preProcess en la función train. También, se puede hacer por separado.

Ajustamos el algoritmo a los datos

```{r}
set.seed(SEED)

knn_sencillo <- train(diagnostico_pro ~ ., 
                      data = df_knn_sencillo_train, 
                      method = METODO_KNN, 
                      tuneGrid = grid, 
                      trControl = train_control)
knn_sencillo

# Este paquete también nos permite graficar como varía la métrica usada para elegir el valor de k óptimo
plot(knn_sencillo)
```

Por último vemos como perfoma el modelo con el test

```{r}
graficar_curva_roc(knn_sencillo, 
                   df_knn_sencillo_test, 
                   nivel_positivo = NOMBRE_NIVEL_POSITIVO_VAR_RESPUESTA, 
                   var_respuesta = NOMBRE_VAR_RESPUESTA,
                   type_predict = TYPE_PREDICT_KNN)
```

## Ejemplo Más Complejo

```{r, results = 'hide'}
vars_knn_complejo <- c("diagnostico_pro", "d1", "d2", "d3", "d4", "d5", "edad", "educ", "empleo", "genero")
df_knn_complejo <- datos %>% select(all_of(vars_knn_complejo)) %>% drop_na()
glimpse(df_knn_complejo)
```
Primero vamos a hacer un preprocesamiento de los datos. Basicamente serán dos tareas:

* Normalizar los datos: (x - xmin) / (xmax - xmin).
* Crear dummy variables para todas las categóricas, excepto la daignostico_pro.

Comenzamos con la normaliación.
```{r}
# Separamos, para que todo lo que hagamos no afecte a la var respuesta
df_x <- df_knn_complejo[,1]
df_y <- df_knn_complejo[,-1]

# Normalizamos los datos, esta función ignora a las factores así que en realidad no pasa nada por tener todas las predictoras juntas.
df_y_normalizado <- df_y %>% 
  preProcess(method = PRE_PROCESS_NORMALIZAR) %>% 
  predict(df_y) %>% 
  data.frame()

# Verificamos que se haya realizado correctamente, ahora todos los xmin y xmax son 0 y 1 respectivamente
df_y_normalizado %>% 
  select(where(is.numeric)) %>% 
  summary()

```
Creamos las variables dummy 

```{r}
# Creación variables dummy
df_y_normalizado_dummy <- dummyVars(~., df_y_normalizado) %>% 
  predict(df_y_normalizado) %>% 
  data.frame()

# Una vez hecho esto podemos vovler a juntar los datos
df_knn_complejo_split <- cbind(df_x, df_y_normalizado_dummy)
```

Separamos los datos

```{r}
set.seed(SEED)
indices_train <- createDataPartition(df_knn_complejo_split$diagnostico_pro, p = PORCENTAJE_TRAIN)[[1]]

df_knn_complejo_train <- df_knn_complejo_split[indices_train,]
df_knn_complejo_test <- df_knn_complejo_split[-indices_train,]

# Verificamos
nrow(df_knn_complejo_split) == nrow(df_knn_complejo_test) + nrow(df_knn_complejo_train)
```
Para buscar el K óptimo, vamos a utilizar 10-fold cross-validation. Vamos a usar valores de k desde 3 hasta 20

```{r}
# Grilla con los valores de k
grid_train <- expand.grid(k = seq(K_MIN, K_MAX))

# Control de entrenamineto
trian_control <- trainControl(method = METODO_CROSS_VALIDATION, number = K_FOLD)
```

Entrenamos el modelo

```{r}
knn_complejo <- train(diagnostico_pro ~ .,
                      df_knn_complejo_train,
                      method = METODO_KNN,
                      tuneGrid = grid_train)

knn_complejo
```

Solo porque podemos, vemos el gráfico de cómo elige el Kmax

```{r}
plot(knn_complejo)
```

Observamos como es el AUROC

```{r}
graficar_curva_roc(knn_complejo,
                   df_knn_complejo_test, 
                   nivel_positivo = NOMBRE_NIVEL_POSITIVO_VAR_RESPUESTA, 
                   var_respuesta = NOMBRE_VAR_RESPUESTA, 
                   type_predict = TYPE_PREDICT_KNN)
```

## Ejemplo Avanzando de A Poco

Vamos a probar como cambia el modelo a medida que agregamos más variables. Por cada submodelo lo que hacemos es:

* Normalizar variables numéricas.
* Crear variables dummy para categóricas.
* Dividir los datos.
* Entrenar un nuevo modelo.
* Calcular el AUROC.

Siempre vamos a usar la misma forma de seleccionar el mismo caso así que defenimos un train_control y una grid para todos los casos.

```{r}
train_control <- trainControl(method = METODO_CROSS_VALIDATION, numbers = K_FOLD)
grid <- expand.grid(k = seq(K_MIN, K_MAX, AVANCE_k))
```

Las variables que vamos a usar son

```{r}
var_predictoras <- c("d1", 
                     "d2",
                     "d3",
                     "d4",
                     "d5",
                     "edad",
                     "educ",
                     "empleo",
                     "genero",
                     "estado_marital",
                     "facilidad_celular",
                     "F0semitoneFrom27.5Hz_sma3nz_stddevNorm",
                     "F0semitoneFrom27.5Hz_sma3nz_amean",
                     "F0semitoneFrom27.5Hz_sma3nz_percentile20.0",
                     "F0semitoneFrom27.5Hz_sma3nz_percentile50.0",
                     "F0semitoneFrom27.5Hz_sma3nz_percentile80.0",
                     "F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope",
                     "F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope",
                     "F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope",
                     "jitterLocal_sma3nz_amean",
                     "jitterLocal_sma3nz_stddevNorm",
                     "shimmerLocaldB_sma3nz_amean",
                     "shimmerLocaldB_sma3nz_stddevNorm")

# Verificamos que no tengan muchos nulos
datos[,var_predictoras] %>% 
  map_int(~ sum(is.na(.x)))
```


```{r}
df_resumen_resultados <- data.frame()

for(i in seq_along(var_predictoras)){
  
    # Obtenemos las primera i variables predictoras
    x <- var_predictoras[1:i]
    
    # Creamos dos dfs para tratar individualmente a las vars predictoras y respuesta
    df_x <- datos %>% select(all_of(x))
    df_y <- datos %>% select(all_of(NOMBRE_VAR_RESPUESTA))
    
    # Primero normalizamos las vars numericas
    df_x_normalizado <- df_x %>% 
      preProcess(method = PRE_PROCESS_NORMALIZAR) %>% 
      predict(df_x) %>% 
      data.frame()
    
    # Segundo creamos las variables dummy
    df_x_normalizado_dummy <- dummyVars(~., df_x_normalizado) %>% 
      predict(df_x_normalizado) %>% 
      data.frame()
    
    # Juntamos la respuesta con las predictoras tratadas en un df
    df <- cbind(df_y, df_x_normalizado_dummy)
    
    # Realizamos la partición
    set.seed(SEED)
    
    indices_train <- createDataPartition(df[[NOMBRE_VAR_RESPUESTA]], 
                                         p = PORCENTAJE_TRAIN)[[1]]
    
    df_train <- df[indices_train,]
    df_test <- df[-indices_train,]
    
    # Ajustamos el modelo
    knn <- train(x = df_train %>% select(-NOMBRE_VAR_RESPUESTA),
                 y = df_train[[NOMBRE_VAR_RESPUESTA]],
                 method = METODO_KNN,
                 trControl = train_control, 
                 tuneGrid = grid)
    
        
    # Calculamos el AUROC con los datos de test
    auroc <- calcular_auroc(knn,
                            df_test, 
                            nivel_positivo = NOMBRE_NIVEL_POSITIVO_VAR_RESPUESTA, 
                            var_respuesta = NOMBRE_VAR_RESPUESTA, 
                            type_predict = TYPE_PREDICT_KNN)
    
    print(round(auroc, 4))
    
    # Agregamos una fila al df con los resultados
    if(nrow(df_resumen_resultados) == 0){
      df_resumen_resultados <- data.frame("NroPredictoras" = length(x), 
                                          "k" = knn$bestTune[[1]], 
                                          "Predictoras" = paste(x, collapse = " "), 
                                          "AUROC" = auroc)
    } else {
      df_resumen_resultados <- df_resumen_resultados %>% 
        add_row(NroPredictoras = length(x), 
                k = knn$bestTune[[1]], 
                Predictoras = paste(x, collapse = " "), 
                AUROC = auroc)  
    }
    
}

df_resumen_resultados
```

