---
title: "KNN"
author: Tomás Sánchez Grigioni
output: html_notebook
---

# Bibliotecas

```{r}
library(tidyverse)
library(caret)
library(pROC)

source("../R/Utils.R")
```

# Constantes y otros

```{r}
# Para cargar archivos
PATH_DATOS_IN <- "../data/bd_final.csv"

FILE_COLUMN_SEPARATOR <- ";"
FILE_DECIMAL_SEPARATOR <- "."

# Para CARET
SEED <- 12345
PORCENTAJE_TRAIN <- 0.7

PRE_PROCESS_NORMALIZAR <- "range"
METODO_KNN <- "knn"
```

# Cargar datos

```{r}
datos_crudos <- read.table(PATH_DATOS_IN, header = TRUE, sep = FILE_COLUMN_SEPARATOR, dec = FILE_DECIMAL_SEPARATOR)
```

# Manipulación de datos

```{r}
glimpse(datos_crudos)
```
Solo hacemos que las variables que aparecen como <chr> pasen a ser factores

```{r}
datos <- datos_crudos %>% 
  map_dfr(~ if(is.character(.x)) { as.factor(.x) } else { .x })

glimpse(datos)
```

# Aplicar algoritmo KNN

## Ejemplo sencillo

Para hacer algo sencillo, solo usamos dos variables numéricas individuales

```{r}
vars_knn_sencillo <- c("diagnostico_pro", "d1", "d2")
```

Creamos un nuevo df con las variables elegidas

```{r}
df_knn_sencillo <- datos %>% select(all_of(vars_knn_sencillo))
glimpse(df_knn_sencillo)
```

Hacemos un pequeño grafico de d1 vs d2 mostrando a que clase de diagnostico_pro pertenece

```{r}
ggplot(df_knn_sencillo, aes(d1, d2, color = diagnostico_pro, shape = diagnostico_pro)) +
  geom_point() +
  theme_bw()
```
Observamos que se solapan bastante estos datos, pero igual vamos a aplicar el algoritmo para hacer el ejemplo.

```{r}
# Particionar datos
set.seed(SEED)

indices_train <- createDataPartition(df_knn_sencillo$diagnostico_pro, p = PORCENTAJE_TRAIN, list = FALSE) %>% as.vector()

df_knn_sencillo_train <- df_knn_sencillo[indices_train,]
df_knn_sencillo_test <- df_knn_sencillo[-indices_train,]

nrow(df_knn_sencillo_test)
nrow(df_knn_sencillo_train)
```

En este algoritmo hay que definir un valor de k. Para esto lo que vamos a usar es el método de 10-fold cross-validation.

```{r}
# Definimos todos los valores de k a probar.
# Observamos como se debe llamar el parámetro según el modelo que voy a usar, para nuestro caso "knn".
getModelInfo(model = "knn")

grid <- expand.grid(k = seq(1, 15, 1))
grid
```

Ahora, tenemos que especificar la forma de que vamos a obtener el valor de k óptimo.

```{r}
train_control <- trainControl(method = "cv", number = 10)
```


Normalizamos los datos, es decir que los dejamos en el rango [0, 1]. Para esto especificamos el parámetro preProcess en la función train. También, se puede hacer por separado.

Ajustamos el algoritmo a los datos

```{r}
set.seed(SEED)

# range = normalizar
# scale and center = standarizar
knn_sencillo <- train(diagnostico_pro ~ ., 
                      data = df_knn_sencillo_train, 
                      method = METODO_KNN, 
                      preProcess = PRE_PROCESS_NORMALIZAR, 
                      tuneGrid = grid, 
                      trControl = train_control)
knn_sencillo

# Este paquete también nos permite graficar como varía la métrica usada para elegir el valor de k óptimo
plot(knn_sencillo)
```

Por último vemos como perfoma el modelo con el test

```{r}
graficar_curva_roc(knn_sencillo, df_knn_sencillo_test, nivel_positivo = "true", var_respuesta = "diagnostico_pro")
```

## Ejemplo Más Complejo

```{r}
vars_knn_complejo <- c("diagnostico_pro", "d1", "d2", "d3", "d4", "d5", "edad", "es_cuidador", "educ", "empleo", "genero")
df_knn_complejo <- datos %>% select(all_of(vars_knn_complejo)) %>% drop_na()
glimpse(df_knn_complejo)
```
Separamos los datos

```{r}
set.seed(SEED)
indices_train <- createDataPartition(df_knn_complejo$diagnostico_pro, p = PORCENTAJE_TRAIN)[[1]]

df_knn_complejo_train <- df_knn_complejo[indices_train,]
df_knn_complejo_test <- df_knn_complejo[-indices_train,]

# Verificamos
nrow(df_knn_complejo) == nrow(df_knn_complejo_test) + nrow(df_knn_complejo_train)
```
Para buscar el K óptimo, vamos a utilizar 10-fold cross-validation. Vamos a usar valores de k desde 3 hasta 20

```{r}
# Grilla con los valores de k
grid_train <- expand.grid(k = 3:20)

# Control de entrenamineto
trian_control <- trainControl(method = "cv", number = 10)

# Creamos variables dummy
as <- predict(dummyVars(diagnostico_pro ~ ., df_knn_complejo_train), df_knn_complejo_train)
```

Entrenamos el modelo

```{r}
knn_complejo <- train(diagnostico_pro ~ .,
                      df_knn_complejo_train,
                      method = METODO_KNN,
                      preProcess = PRE_PROCESS_NORMALIZAR,
                      trControl = train_control,
                      tuneGrid = grid_train)
```



